{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist\n",
    "from functools import reduce\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_b = pd.read_excel('Train/train_bureau.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_d = pd.read_excel('Train/train_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_b = pd.read_excel('Test/test_bureau.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d = pd.read_excel('Test/test_Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bb = train_b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bb = test_b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Treatment:\n",
    "#     -categorical vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id -dont do it\n",
    "# self indiactor -nochange\n",
    "# match type- not req\n",
    "# acct type -required 3 columns chosen for remaning crosstab then combine cols\n",
    "    -\n",
    " #contributor type ARC is not ptesent in test so crosstab and then delete arc   \n",
    "# ownership indicator no rpoblem\n",
    "# account status not present in test Sold/Purchased ,Cancelled cross tab then delete                            \n",
    "# credit limit CREDIT-LIMIT/SANC AMT  DISBURSED-AMT/HIGH CREDIT kbindiscretization\n",
    "# installment not present in test data F04 F07  F08 crosstab then delete it\n",
    "# asset class 2 not ptresent in test crosstab and remove it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_SELF_INDICATOR=pd.crosstab(train.ID,train['SELF-INDICATOR'],dropna= True).reset_index()\n",
    "test_SELF_INDICATOR=pd.crosstab(test.ID,test['SELF-INDICATOR'],dropna= True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_MATCH_TYPE=pd.crosstab(train.ID,train['MATCH-TYPE'],dropna= True).reset_index()\n",
    "test_MATCH_TYPE=pd.crosstab(test.ID,test['MATCH-TYPE'],dropna= True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Property Loan', 'SHG Individual', 'Commercial Vehicle Loan', 'Construction Equipment Loan', 'Loan to Professional', 'Overdraft', 'Microfinance Business Loan', 'Business Non-Funded Credit Facility-Priority Sector-Agriculture', 'Two-Wheeler Loan', 'Business Loan General', 'Personal Loan', 'Loan Against Shares / Securities', 'Microfinance Personal Loan', 'Consumer Loan', 'Tractor Loan', 'Business Loan Unsecured', 'Prime Minister Jaan Dhan Yojana - Overdraft', 'Business Non-Funded Credit Facility General', 'Business Loan - Secured', 'Secured Credit Card', 'Auto Loan (Personal)', 'Gold Loan', 'Pradhan Mantri Awas Yojana - CLSS', 'Individual', 'Business Loan Against Bank Deposits', 'Microfinance Others', 'Mudra Loans   Shishu / Kishor / Tarun', 'Non-Funded Credit Facility', 'Business Loan Priority Sector  Others', 'Business Loan Priority Sector  Agriculture', 'Used Car Loan', 'Credit Card', 'Commercial Equipment Loan', 'Kisan Credit Card', 'Other', 'Loan Against Bank Deposits', 'Microfinance Housing Loan', 'Fleet Card', 'Business Loan Priority Sector  Small Business', 'Education Loan', 'JLG Individual', 'Housing Loan', 'Business Non-Funded Credit Facility-Priority Sector- Small Business', 'Corporate Credit Card']\n"
     ]
    }
   ],
   "source": [
    "x = set(train_bb['ACCT-TYPE'].unique())  \n",
    "y = set(test_bb['ACCT-TYPE'].unique()) \n",
    "common = x.intersection(y)\n",
    "print(list(common)) #now decide cols to keep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ACCT_TYPE=pd.crosstab(train.ID,train['ACCT-TYPE'],dropna= True).reset_index()\n",
    "test_ACCT_TYPE=pd.crosstab(test.ID,test['ACCT-TYPE'],dropna= True).reset_index()\n",
    "\n",
    "cols_to_keep =['Tractor Loan','Gold Loan','Business Loan Priority Sector  Agriculture']\n",
    "\n",
    "train_ACCT_TYPE[\"Others\"] = pd.DataFrame(train_ACCT_TYPE.drop(columns=cols_to_keep).sum(axis=1))\n",
    "test_ACCT_TYPE[\"Others\"] = pd.DataFrame(test_ACCT_TYPE.drop(columns=cols_to_keep).sum(axis=1))\n",
    "filter_cols =cols_to_keep + ['Others'] \n",
    "train_ACCT_TYPE = train_ACCT_TYPE.filter(filter_cols)\n",
    "test_ACCT_TYPE = test_ACCT_TYPE.filter(filter_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CONTRIBUTOR_TYPE=pd.crosstab(train.ID,train['CONTRIBUTOR-TYPE'],dropna= True).drop(columns = ['ARC']).reset_index()\n",
    "test_CONTRIBUTOR_TYPE=pd.crosstab(test.ID,test['CONTRIBUTOR-TYPE'],dropna= True).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_OWNERSHIP_IND=pd.crosstab(train.ID,train['OWNERSHIP-IND'],dropna= True).reset_index()\n",
    "test_OWNERSHIP_IND=pd.crosstab(test.ID,test['OWNERSHIP-IND'],dropna= True).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ACCOUNT_STATUS=pd.crosstab(train.ID,train['ACCOUNT-STATUS'],dropna= True).drop(columns=['Sold/Purchased','Cancelled']).reset_index()\n",
    "test_ACCOUNT_STATUS=pd.crosstab(test.ID,test['ACCOUNT-STATUS'],dropna= True).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_INSTALLMENT_FREQUENCY=pd.crosstab(train.ID,train['INSTALLMENT-FREQUENCY'],dropna= True).drop(columns=['F04','F07','F08']).reset_index()\n",
    "test_INSTALLMENT_FREQUENCY=pd.crosstab(test.ID,test['INSTALLMENT-FREQUENCY'],dropna= True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ASSET_CLASS=pd.crosstab(train.ID,train['ASSET_CLASS'],dropna= True).drop(columns=['2']).reset_index()\n",
    "test_ASSET_CLASS=pd.crosstab(test.ID,test['ASSET_CLASS'],dropna= True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencoder(train,test,cols=[]):\n",
    "    \n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    #object_cols = catVar1(train) #catVar1 gives desired categorical column and not all object columns\n",
    "    object_cols=cols\n",
    "    print(object_cols)\n",
    "    \n",
    "    OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "    OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train[object_cols]))\n",
    "    OH_cols_test = pd.DataFrame(OH_encoder.transform(test[object_cols]))\n",
    "\n",
    "    # One-hot encoding removed index; put it back\n",
    "    OH_cols_train.index = train.index\n",
    "    OH_cols_test.index = test.index\n",
    "\n",
    "    ##hack for restoring columns names just like get dummies\n",
    "    column_name = OH_encoder.get_feature_names(object_cols)\n",
    "    OH_cols_train.columns = column_name\n",
    "    OH_cols_test.columns = column_name\n",
    "    \n",
    "\n",
    "    # Remove desired categorical columns (will replace with one-hot encoding)\n",
    "    num_train = train.drop(object_cols, axis=1)\n",
    "    num_test = test.drop(object_cols, axis=1)\n",
    "\n",
    "    # Add one-hot encoded columns to numerical/remaining features\n",
    "    OH_train = pd.concat([num_train, OH_cols_train], axis=1)\n",
    "    OH_test = pd.concat([num_test, OH_cols_test], axis=1)\n",
    "    \n",
    "\n",
    "    \n",
    "    print(OH_train.shape,OH_test.shape)\n",
    "    \n",
    "    \n",
    "    return OH_train,OH_test\n",
    "\n",
    "def targetencoding(train,test,y_train,drop=False,cols=[]):\n",
    "    import category_encoders as ce\n",
    "    # Create the encoder itself\n",
    "    cat_features = cols\n",
    "    print(f'targest emcoding for features {cat_features}')\n",
    "    target_enc = ce.TargetEncoder(cols=cat_features)\n",
    "\n",
    "    \n",
    "\n",
    "    # Fit the encoder using the categorical features and target\n",
    "    target_enc.fit(train[cat_features], y_train)\n",
    "    \n",
    "\n",
    "    # Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "    traintrgtenc = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
    "    testtrgtenc = test.join(target_enc.transform(test[cat_features]).add_suffix('_target'))\n",
    "\n",
    "    if drop :\n",
    "        traintrgtenc = traintrgtenc.drop(cat_features, axis =1)\n",
    "        testtrgtenc = testtrgtenc.drop(cat_features, axis =1)\n",
    "\n",
    "    \n",
    "    print(traintrgtenc.shape,testtrgtenc.shape)\n",
    "    \n",
    "    return traintrgtenc,testtrgtenc\n",
    "\n",
    "\n",
    "def ordinalencoding(train,test,y_train,mapping,drop=False,cols=[]):\n",
    "    import category_encoders as ce\n",
    "    # Create the encoder itself\n",
    "    cat_features = cols\n",
    "    print(f'ordinal encoding for features {cat_features}')\n",
    "    target_enc = ce.OrdinalEncoder(cols=cat_features,mapping = mapping)\n",
    "\n",
    "    \n",
    "\n",
    "    # Fit the encoder using the categorical features and target\n",
    "    target_enc.fit(train[cat_features], y_train)\n",
    "    \n",
    "\n",
    "    # Transform the features, rename the columns with _target suffix, and join to dataframe\n",
    "    traintrgtenc = train.join(target_enc.transform(train[cat_features]).add_suffix('_ordinal'))\n",
    "    testtrgtenc = test.join(target_enc.transform(test[cat_features]).add_suffix('_ordinal'))\n",
    "\n",
    "    if drop :\n",
    "        traintrgtenc = traintrgtenc.drop(cat_features, axis =1)\n",
    "        testtrgtenc = testtrgtenc.drop(cat_features, axis =1)\n",
    "\n",
    "    \n",
    "    print(traintrgtenc.shape,testtrgtenc.shape)\n",
    "    \n",
    "    return traintrgtenc,testtrgtenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bb['DISBURSED-AMT/HIGH CREDIT'] = train_b['DISBURSED-AMT/HIGH CREDIT'].str.replace(',', '').astype('float')\n",
    "test_bb['DISBURSED-AMT/HIGH CREDIT'] = test_b['DISBURSED-AMT/HIGH CREDIT'].str.replace(',', '').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bb['CURRENT-BAL'] = train_b['CURRENT-BAL'].fillna(0)\n",
    "test_bb['CURRENT-BAL'] = test_b['CURRENT-BAL'].fillna(0)\n",
    "train_bb['CURRENT-BAL'] = train_b['CURRENT-BAL'].str.replace(',', '').astype('float')\n",
    "test_bb['CURRENT-BAL'] = test_b['CURRENT-BAL'].str.replace(',', '').astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_CURRENT = train_bb[['CURRENT-BAL','ID']].dropna()\n",
    "test_CURRENT = test_bb[['CURRENT-BAL','ID']].dropna()\n",
    "\n",
    "enc = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')\n",
    "enc.fit(train_bb['CURRENT-BAL'].dropna().values.reshape(-1,1))\n",
    "\n",
    "train_CURRENT['CURRENT-BAL'] = enc.transform(train_CURRENT['CURRENT-BAL'].values.reshape(-1,1))\n",
    "test_CURRENT['CURRENT-BAL']= enc.transform(test_CURRENT['CURRENT-BAL'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_CURRENT=pd.crosstab(train_CURRENT.ID,train_CURRENT['CURRENT-BAL'],dropna= True).reset_index()\n",
    "test_CURRENT=pd.crosstab(test_CURRENT.ID,test_CURRENT['CURRENT-BAL'],dropna= True).reset_index()\n",
    "test_CURRENT['3.0']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_DISBURSED = train_bb[['DISBURSED-AMT/HIGH CREDIT','ID']].dropna()\n",
    "test_DISBURSED = test_bb[['DISBURSED-AMT/HIGH CREDIT','ID']].dropna()\n",
    "\n",
    "enc = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')\n",
    "enc.fit(train_bb['DISBURSED-AMT/HIGH CREDIT'].dropna().values.reshape(-1,1))\n",
    "\n",
    "train_DISBURSED['DISBURSED-AMT/HIGH CREDIT'] = enc.transform(train_DISBURSED['DISBURSED-AMT/HIGH CREDIT'].values.reshape(-1,1))\n",
    "test_DISBURSED['DISBURSED-AMT/HIGH CREDIT']= enc.transform(test_DISBURSED['DISBURSED-AMT/HIGH CREDIT'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_DISBURSED=pd.crosstab(train_DISBURSED.ID,train_DISBURSED['DISBURSED-AMT/HIGH CREDIT'],dropna= True).reset_index()\n",
    "test_DISBURSED=pd.crosstab(test_DISBURSED.ID,test_DISBURSED['DISBURSED-AMT/HIGH CREDIT'],dropna= True).reset_index()\n",
    "test_DISBURSED['2.0']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discretisation baes on clusters\n",
    "\n",
    "train_tenure = train_bb[['TENURE','ID']].dropna()\n",
    "test_tenure = test_bb[['TENURE','ID']].dropna()\n",
    "\n",
    "enc = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='kmeans')\n",
    "enc.fit(train_bb['TENURE'].dropna().values.reshape(-1,1))\n",
    "\n",
    "train_tenure['TENURE'] = enc.transform(train_tenure['TENURE'].values.reshape(-1,1))\n",
    "test_tenure['TENURE']= enc.transform(test_tenure['TENURE'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tenure=pd.crosstab(train_tenure.ID,train_tenure['TENURE'],dropna= True).reset_index()\n",
    "test_tenure=pd.crosstab(test_tenure.ID,test_tenure['TENURE'],dropna= True).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [train_b.ID,train_SELF_INDICATOR,train_INSTALLMENT_FREQUENCY,train_ACCOUNT_STATUS,train_OWNERSHIP_IND,\n",
    "              train_CONTRIBUTOR_TYPE,train_ACCT_TYPE,train_MATCH_TYPE,train_ASSET_CLASS,train_CURRENT,train_DISBURSED,\n",
    "              train_tenure]\n",
    "final_df_train_beauro = reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [test_b.ID,test_SELF_INDICATOR,test_INSTALLMENT_FREQUENCY,test_ACCOUNT_STATUS,test_OWNERSHIP_IND,\n",
    "              test_CONTRIBUTOR_TYPE,test_ACCT_TYPE,test_MATCH_TYPE,test_ASSET_CLASS,test_CURRENT,test_DISBURSED,test_tenure]\n",
    "final_df_test_beauro = reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### now train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd = train_d.copy()\n",
    "test_dd = test_d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>InstlmentMode</th>\n",
       "      <th>LoanStatus</th>\n",
       "      <th>PaymentMode</th>\n",
       "      <th>BranchID</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>AssetCost</th>\n",
       "      <th>AmountFinance</th>\n",
       "      <th>DisbursalAmount</th>\n",
       "      <th>...</th>\n",
       "      <th>AssetID</th>\n",
       "      <th>ManufacturerID</th>\n",
       "      <th>SupplierID</th>\n",
       "      <th>LTV</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>State</th>\n",
       "      <th>ZiPCODE</th>\n",
       "      <th>Top-up Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Arrear</td>\n",
       "      <td>Closed</td>\n",
       "      <td>PDC_E</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>450000</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>275000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4022465</td>\n",
       "      <td>1568</td>\n",
       "      <td>21946</td>\n",
       "      <td>61.11</td>\n",
       "      <td>M</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35833.33</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>464993.0</td>\n",
       "      <td>&gt; 48 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Advance</td>\n",
       "      <td>Closed</td>\n",
       "      <td>PDC</td>\n",
       "      <td>333</td>\n",
       "      <td>47</td>\n",
       "      <td>485000</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>350000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4681175</td>\n",
       "      <td>1062</td>\n",
       "      <td>34802</td>\n",
       "      <td>70.00</td>\n",
       "      <td>M</td>\n",
       "      <td>23.0</td>\n",
       "      <td>666.67</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>466001.0</td>\n",
       "      <td>No Top-up Service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quatrly</td>\n",
       "      <td>Arrear</td>\n",
       "      <td>Active</td>\n",
       "      <td>Direct Debit</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>690000</td>\n",
       "      <td>519728.0</td>\n",
       "      <td>519728.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25328146</td>\n",
       "      <td>1060</td>\n",
       "      <td>127335</td>\n",
       "      <td>69.77</td>\n",
       "      <td>M</td>\n",
       "      <td>39.0</td>\n",
       "      <td>45257.00</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>462030.0</td>\n",
       "      <td>12-18 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Advance</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Billed</td>\n",
       "      <td>125</td>\n",
       "      <td>48</td>\n",
       "      <td>480000</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>400000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13021591</td>\n",
       "      <td>1060</td>\n",
       "      <td>25094</td>\n",
       "      <td>80.92</td>\n",
       "      <td>M</td>\n",
       "      <td>24.0</td>\n",
       "      <td>20833.33</td>\n",
       "      <td>MADHYA PRADESH</td>\n",
       "      <td>473335.0</td>\n",
       "      <td>&gt; 48 Months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>Arrear</td>\n",
       "      <td>Closed</td>\n",
       "      <td>Billed</td>\n",
       "      <td>152</td>\n",
       "      <td>44</td>\n",
       "      <td>619265</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3291320</td>\n",
       "      <td>1046</td>\n",
       "      <td>21853</td>\n",
       "      <td>71.05</td>\n",
       "      <td>M</td>\n",
       "      <td>56.0</td>\n",
       "      <td>27313.67</td>\n",
       "      <td>CHATTISGARH</td>\n",
       "      <td>495442.0</td>\n",
       "      <td>36-48 Months</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID Frequency InstlmentMode LoanStatus   PaymentMode  BranchID  Tenure  \\\n",
       "0   1   Monthly        Arrear     Closed         PDC_E         1      48   \n",
       "1   2   Monthly       Advance     Closed           PDC       333      47   \n",
       "2   3   Quatrly        Arrear     Active  Direct Debit         1      68   \n",
       "3   7   Monthly       Advance     Closed        Billed       125      48   \n",
       "4   8   Monthly        Arrear     Closed        Billed       152      44   \n",
       "\n",
       "   AssetCost  AmountFinance  DisbursalAmount  ...   AssetID ManufacturerID  \\\n",
       "0     450000       275000.0         275000.0  ...   4022465           1568   \n",
       "1     485000       350000.0         350000.0  ...   4681175           1062   \n",
       "2     690000       519728.0         519728.0  ...  25328146           1060   \n",
       "3     480000       400000.0         400000.0  ...  13021591           1060   \n",
       "4     619265       440000.0         440000.0  ...   3291320           1046   \n",
       "\n",
       "  SupplierID    LTV  SEX   AGE  MonthlyIncome           State   ZiPCODE  \\\n",
       "0      21946  61.11    M  49.0       35833.33  MADHYA PRADESH  464993.0   \n",
       "1      34802  70.00    M  23.0         666.67  MADHYA PRADESH  466001.0   \n",
       "2     127335  69.77    M  39.0       45257.00  MADHYA PRADESH  462030.0   \n",
       "3      25094  80.92    M  24.0       20833.33  MADHYA PRADESH  473335.0   \n",
       "4      21853  71.05    M  56.0       27313.67     CHATTISGARH  495442.0   \n",
       "\n",
       "        Top-up Month  \n",
       "0        > 48 Months  \n",
       "1  No Top-up Service  \n",
       "2       12-18 Months  \n",
       "3        > 48 Months  \n",
       "4       36-48 Months  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd['SEX'] = train_dd['SEX'].fillna(train_dd['SEX'].mode()[0])\n",
    "test_dd['SEX'] = test_dd['SEX'].fillna(test_dd['SEX'].mode()[0])\n",
    "\n",
    "train_dd['AGE'] = train_dd['AGE'].fillna(train_dd['AGE'].mode()[0])\n",
    "test_dd['AGE'] = test_dd['AGE'].fillna(test_dd['AGE'].mode()[0])\n",
    "\n",
    "train_dd['MonthlyIncome'] = train_dd['MonthlyIncome'].fillna(train_dd['MonthlyIncome'].mode()[0])\n",
    "test_dd['MonthlyIncome'] = test_dd['MonthlyIncome'].fillna(test_dd['MonthlyIncome'].mode()[0])\n",
    "\n",
    "train_dd['ZiPCODE']  =train_dd['ZiPCODE'].fillna(method = 'ffill').astype('int') \n",
    "test_dd['ZiPCODE']  =test_dd['ZiPCODE'].fillna(method = 'ffill').astype('int') \n",
    "\n",
    "train_dd =train_dd.fillna(method = 'ffill') \n",
    "test_dd =test_dd.fillna(method = 'ffill') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd['AuthDate'] = pd.to_datetime(train_d['AuthDate'] ,errors='coerce')\n",
    "test_dd['AuthDate'] = pd.to_datetime(test_d['AuthDate'] ,errors='coerce')\n",
    "\n",
    "train_dd['DisbursalDate'] = pd.to_datetime(train_d['DisbursalDate'] ,errors='coerce')\n",
    "test_dd['DisbursalDate'] = pd.to_datetime(test_d['DisbursalDate'] ,errors='coerce')\n",
    "\n",
    "train_dd['MaturityDAte'] = pd.to_datetime(train_d['MaturityDAte'] ,errors='coerce')\n",
    "test_dd['MaturityDAte'] = pd.to_datetime(test_d['MaturityDAte'] ,errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd['AuthtoMatureDays'] = train_dd['AuthDate'] - train_dd['MaturityDAte']\n",
    "test_dd['AuthtoMatureDays'] = test_dd['AuthDate'] - test_dd['MaturityDAte']\n",
    "\n",
    "train_dd['AuthtoDisDays'] = train_dd['AuthDate'] - train_dd['DisbursalDate']\n",
    "test_dd['AuthtoDisDays'] = test_dd['AuthDate'] - test_dd['DisbursalDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd['AuthYear'] = train_dd['AuthDate'].dt.year \n",
    "test_dd['AuthtYear'] = test_dd['AuthDate'].dt.year \n",
    "train_dd['AuthMonth'] = train_dd['AuthDate'].dt.month \n",
    "test_dd['AuthtMonth'] = test_dd['AuthDate'].dt.month \n",
    "\n",
    "\n",
    "train_dd['MaturityYear'] = train_d['MaturityDAte'].dt.year \n",
    "test_dd['MaturityYear'] = test_d['MaturityDAte'].dt.year \n",
    "\n",
    "train_dd['MaturityMonth'] = train_d['MaturityDAte'].dt.month \n",
    "test_dd['MaturityMonth'] = test_d['MaturityDAte'].dt.month "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd = train_dd.drop(columns=['City','Area','AuthDate','DisbursalDate','MaturityDAte'])\n",
    "test_dd = test_dd.drop(columns=['City','Area','AuthDate','DisbursalDate','MaturityDAte'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict = {'No Top-up Service':0, '12-18 Months':1,'18-24 Months':2, '24-30 Months':3, \n",
    "                '30-36 Months':4,'36-48 Months':5,' > 48 Months':6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dd['Top-up Month'] = train_dd['Top-up Month'].replace(mapping_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict_f= [\n",
    "{'col': 'Frequency', 'mapping': {'BI-Monthly':0, 'Monthly': 1, 'Quatrly': 2,  'Half Yearly': 3}}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ordinal encoding for features ['Frequency']\n",
      "(128655, 24) (14745, 23)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    }
   ],
   "source": [
    "f1,f2 = ordinalencoding(train_dd,test_dd,train_dd['Top-up Month'],drop =True,cols=['Frequency'],mapping= mapping_dict_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['InstlmentMode', 'LoanStatus', 'SEX']\n",
      "(128655, 27) (14745, 26)\n"
     ]
    }
   ],
   "source": [
    "f11,f22 = onehotencoder(f1,f2,cols=['InstlmentMode','LoanStatus','SEX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targest emcoding for features ['PaymentMode', 'State', 'BranchID', 'ZiPCODE', 'ManufacturerID']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\category_encoders\\utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128655, 27) (14745, 26)\n"
     ]
    }
   ],
   "source": [
    "f111,f222 = targetencoding(f11,f22,f11['Top-up Month'],drop=True,cols=['PaymentMode','State','BranchID','ZiPCODE','ManufacturerID']) #because branch id and area same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [f111,final_df_train_beauro]\n",
    "final_df_test = reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = [f222,final_df_test_beauro]\n",
    "final_df_test = reduce(lambda left, right: pd.merge(left, right, on='ID', how='left'), dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Null value treatment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
